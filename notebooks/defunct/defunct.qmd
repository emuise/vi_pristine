---
title: "Untitled"
editor: visual
---

OLD Now that we have base and treatment parquet files, we need to calculate the mahalanobis distance for every pixel to it's matched top 10% protected area pixels

```{r}
split_pqs <- list.files(split_loc, full.names = T)

str_vars <- c("elev_p95", "total_biomass", "percentage_first_returns_above_2m", "elev_cv")
dhi_vars <- c("CumDHI", "VarDHI", "MinDHI")
all_vars <- c(str_vars, dhi_vars)
all_vars_names <- c("height", "biomass", "cover", "complexity", "cum", "var", "min")

x <- split_pqs[[50]]

filt_list <- list(
  c("elev_p95"),
  c("elev_p95", "percentage_first_returns_above_2m"),
  c("percentage_first_returns_above_2m"),
  c("CumDHI"),
  c("VarDHI")
)

dist_list <- list(all_vars, str_vars, dhi_vars)

crossed <- crossing(filt_list, dist_list)

tibble(filter_distance = 0, n = 0, reason = 0) %>%
  head(0) %>%
  write_csv(here::here(tab_loc, "mahal_fail_reasons.csv"))

split_pqs %>%
  map(\(x) {
    # since every file has a matched treatment, just change out the folder
    # to the treatment folder
    
    # read both
    base <- read_parquet(x)
    base_n <- nrow(base)
    y <- here::here(treat_loc, basename(x))
    
    treat <- read_parquet(str_replace(x, "split_strata", "treatment_strata"))
    cutoff <- 0.9
    
    savename <- here::here(mahal_tab_loc, basename(x))
    
    # this function takes the variables that we filter on, variables to 
    # calculate mahalanobis distance on, and a cutoff for the top x% of
    # filtered variables
    # then calcuates the mahalanobis dsitance and returns a tibble
    # which has relevantly named p-values and distances
    
    if(file.exists(savename)) {
      return(savename)
    }
    
    calc_mahal <- function(filter_vars, distance_vars, cutoff) {
      
      # section determines what to save column names as
      clean_filter_names <- all_vars_names[all_vars %in% filter_vars]
      
      var_cuts <- glue("{clean_filter_names}-{cutoff}") %>%
        glue_collapse(sep = "_")
      
      if (length(distance_vars) == 7) {
        dist_name <- "all"
      } else if (length(distance_vars) == 4) {
        dist_name <- "str"
      } else {
        dist_name <- "dhi"
      }
      colname <- glue("{var_cuts}_{dist_name}")
      
      # filter the treatment df such that all filter variables are less than
      # the cutoff, and then seelct only the variables we want to 
      # calculate distance on
      filt_treat <- treat %>%
        # the !! makes it so that the string evaluates the variable,
        # allowing us to do this filter all at once if there are multiple
        filter(if_all(!!filter_vars, .fns = \(x) {
          x >= quantile(x, 0.9)
        })) %>%
        select(all_of(distance_vars))
      
      # nothing meets the criteria
      if(nrow(filt_treat) <= 1) {
        error_tib <- tibble(filter_distance = colname, n = base_n, reason = "Too few filtered samples")
        fwrite(error_tib, file = here::here(tab_loc, "mahal_fail_reasons.csv"), append = T)
        return(tibble("mahal_{colname}" := NA, "p_{colname}" := NA))
      }
      
      # calcuate means
      filt_means <- filt_treat %>%
        summarize(across(everything(), mean)) %>%
        pivot_longer(cols = everything())
      
      # calculate covariance matrix
      filt_cov <- filt_treat %>%
        as.matrix() %>%
        cov()
      
      # matrix is not invertible, can't calculate mahalanobis distance
      if(det(filt_cov) == 0) {
        error_tib <- tibble(filter_distance = colname, n = base_n, reason = "Matrix not invertible")
        fwrite(error_tib, file = here::here(tab_loc, "mahal_fail_reasons.csv"), append = T)
        return(tibble("mahal_{colname}" := NA, "p_{colname}" := NA))
      }
      
      base_mat <- base %>%
        select(all_of(distance_vars)) %>%
        as.matrix()
      
      mahal_dist <- mahalanobis(
        base_mat,
        center = filt_means %>% pull(value),
        cov = filt_cov,
        tol = 1e-50
      )
      
      mahal_pval <- pchisq(mahal_dist, 
                           df = length(distance_vars) - 1, 
                           lower.tail = F) %>%
        round(4)
      
      out <- tibble("mahal_{colname}" := mahal_dist, "p_{colname}" :=mahal_pval)
      
      return(out)
    }
    
    egg <- map2(.x = crossed$filt_list, .y = crossed$dist_list, .f = calc_mahal, cutoff = 0.9)
    
    mahal_tosave <- base %>%
      select(x, y) %>%
      bind_cols(egg)
    
    write_parquet(mahal_tosave, savename)
    savename
  },
  .progress = "Calcuating mahal distance")
```

# mahalanbos distance plots and maps, nn dist map

mahalanobis distance visualization in PCA space

```{r} str_vars <- c("elev_p95",               "total_biomass",               "percentage_first_returns_above_2m",               "elev_cv") dhi_vars <- c("CumDHI", "VarDHI", "MinDHI") all_vars <- c(str_vars, dhi_vars)  x <- "E:/Sync/Masters/04_vi_pristine/strathcona/data/tabs/split_strata/coniferous_2-2-1.parquet"  x_var <- "str_1" y_var <- "str_2"  filter_vars <- "percentage_first_returns_above_2m"  base <- read_parquet(x) treat <- read_parquet(here::here(treat_loc, basename(x)))  treat_plot <- treat %>%   filter(if_all(!!filter_vars, .fns = \(x) {         x >= quantile(x, 0.9)       }))  treat_centre <- treat_plot %>%   select(all_of(c(x_var, y_var))) %>%   summarize(across(everything(), mean))  treat_sds <- treat_plot %>%   select(all_of(c(x_var, y_var))) %>%   summarize(across(everything(), sd))  base_plot <- base %>%   filter(elev_cv <= 1)  f_s_sds <- f_s_pca %>%   filter(elev_cv <= 1) %>%   summarize(across(dhi_1:all_6, sd))  mahal_vis <- f_s_pca %>%   slice_sample(n = 10000) %>%   filter(elev_cv <= 1) %>%   ggplot(aes(x = !!sym(x_var), y = !!sym(y_var))) +   # geom_jitter(alpha = 0.1) +   geom_jitter(data = base_plot %>%                  mutate(egg = disturbance == "No change"), aes(shape = egg), col = "red",               alpha = .5) +   scale_shape_manual(values = c(0, 2), labels = c("Disturbed", "Undisturbed")) +   geom_jitter(     data = treat_plot,     col = "#00b4c090",     size = 1,     height = 0.25,     width = 0.25   ) +   geom_point(     data = treat_centre,     col = "#00b4c0",     fill = "#00b4c0",     size = 5,     shape = 25   ) +   geom_ellipse(     aes(       x0 = treat_centre %>% pull(x_var),       y0 = treat_centre %>% pull(y_var),       a = treat_sds %>% pull(x_var),       b = treat_sds %>% pull(y_var),       angle = 0     ),     alpha = 0.5,     lty = "dashed"   ) +   geom_ellipse(     aes(       x0 = treat_centre %>% pull(x_var),       y0 = treat_centre %>% pull(y_var),       a = treat_sds %>% pull(x_var) * 2,       b = treat_sds %>% pull(y_var) * 2,       angle = 0     ),     alpha = 0.5,     lty = "dashed"   ) +   geom_text(data = tibble(egg = 1),             aes(     x = treat_centre %>% pull(x_var),     y = treat_centre %>% pull(y_var) + treat_sds %>% pull(y_var) + 0.2,     label = "1SD"   )) +   geom_text(data = tibble(egg = 1),             aes(     x = treat_centre %>% pull(x_var),     y = treat_centre %>% pull(y_var) + treat_sds %>% pull(y_var) * 2 + 0.2,     label = "2SD"   )) +   labs(x = "Structure PCA 1", y = "Strucutre PCA 2") +   theme_bw() +   theme(panel.grid = element_blank(),         legend.position = "bottom") +   lims(x = c(-4, 4), y = c(-4, 4))   ggsave(   here::here(figure_loc, "mahalanobis_vis.png"),   plot = mahal_vis,   dpi = 300,   height = 6,   width = 6 )   ggsave(   here::here(figure_loc, "mahalanobis_vis_trans.png"),   plot = mahal_vis +     theme(       panel.grid = element_blank(),       plot.background = element_blank(),       panel.background = element_blank()     ),   dpi = 300,   height = 6,   width = 6,   background = "#00000030" )}
```

mahal distance 10% tallest trees plot

```{r} # undo the qnorm # undo the pchisq(df = 4, lower.tail = F) # redo the pchisq(df = 4, lower.tail = T) # redo the qchisq(df = 1) mahal <- "E:/Sync/Masters/04_vi_pristine/strathcona/data/rasters/mahal/height-0.9_str.dat" %>%   rast()   mahal_df <- mahal %>%   as.data.frame() %>%   as_tibble()  mahal_df %>%   rename(sigma = 1) %>%   count(sigma > 2) %>%   mutate(per = n / sum(n))  mahal_class <- mahal %>%   classify(c(0, 1, 2, 3, 4, Inf))  plot(mahal_class)  ggplot() +   geom_spatraster(data = mahal) +   #theme_void() +   scico::scale_fill_scico_d(     palette = "hawaii",     labels = c("0-1 SD",                "1-2 SD",                "2-3 SD",                "3-4 SD",                "4+ SD"),     na.value = "transparent"   )}
```

# extra stuff

```{r} vi_mahal_df %>%    select(nn_dist_all, nn_dist_30) %>%    mutate(across(everything(), ceiling)) %>%    count(nn_dist_30) %>%    mutate(per = n / sum(n),          cumper = cumsum(per)) %>%   ggplot(aes(x = nn_dist_30, y = cumper)) +    geom_line() +   theme_classic()}
```

Check for single park/ plot single park

```{r} names(vi_pa)  pa_oi <- vi_pa %>%   filter(str_detect(name, "Strath")) %>%   aggregate()  active_layer <- "E:/Sync/Masters/04_vi_pristine/data/rasters/mahal/cum-0.9_dhi.dat" %>%   rast()  buffer_rad <- sqrt(expanse(pa_oi) / pi)  sr <- crop(active_layer, pa_oi %>%        terra::buffer(buffer_rad), mask = T)   sr_class <- sr %>%   classify(c(-999, 1, 2, 3, 4, 999))  ggplot() +   geom_spatraster(data = sr_class) +   geom_spatvector(data = pa_oi, fill = NA, col = "red", linewidth = 1) +   scale_fill_viridis_d(option = "D", na.value = "transparent", labels = c("0", "1", "2", "3 +")) +   theme_void() +   labs(fill = "Sigma Similarity") +   theme(legend.position = "bottom")  ggsave(here::here(figure_loc, "strath.png"), height = 6, width = 6, bg = "transparent")       park_joined <- sr %>%   as.data.frame(xy = T) %>%   as_tibble() %>%   mutate(across(c(x, y), \(x) {round(x, 2)})) %>%   left_join(f_s_pca %>%               mutate(across(c(x, y), \(x) {round(x, 2)})))  park_joined %>%   ggplot(aes(x = human_footprint, y = `cum-0.9_dhi`)) +   geom_point()  park_joined %>%    select(sigma = `cum-0.9_dhi`, human_footprint) %>%    mutate(sigma = as.numeric(cut(sigma, breaks = c(-999, 2, 3, 4, 999))),          human_footprint = as.numeric(cut(human_footprint, breaks = c(-1, 4, 10, 999)))) %>%   count(human_footprint, sigma)}
```

Check what is constrained by climate

```{r} extract_mean_sd <- function(df) {   df %>%       summarize(across(c(CumDHI:total_biomass, dhi_1:all_6), .fns = list(mean = \(x) mean(x, na.rm = T),                                                                          sd = \(x) sd(x, na.rm = T)),                        .names = "{.col}-{.fn}")) %>%       pivot_longer(everything()) %>%       separate(name, into = c("var", "metric"), sep = "-") %>%       pivot_wider(names_from = metric, values_from = value) }   OUTOUT <- wide_scpa %>%   mutate(split_metrics = map(split_file, \(x) {     df <- x %>%       read_parquet() %>%       extract_mean_sd() %>%       mutate(filter = "base")          treat <- x %>%       basename() %>%       here::here(treat_loc, .) %>%       read_parquet()          dfs <- map_dfr(filt_list, \(filter_vars) {       # section determines what to save column names as       clean_filter_names <- all_vars_names[all_vars %in% filter_vars]              var_cuts <- glue("{clean_filter_names}-{cutoff}") %>%         glue_collapse(sep = "_")              filt_treat <- treat %>%         # the !! makes it so that the string evaluates the variable,         # allowing us to do this filter all at once if there are multiple         filter(if_all(!!filter_vars, .fns = \(x) {           x >= quantile(x, cutoff)         })) %>%         extract_mean_sd() %>%         mutate(filter = var_cuts)                   })          bind_rows(dfs, df)   }), .progress = T)  out_unnest <- OUTOUT %>%   unnest(split_metrics)  out_unnest %>%   filter(filter == "base" |            filter == "height-0.9") %>%   pivot_longer(clim_MAP:slope, names_to = "confound", values_to = "confound_value") %>%   select(-pa, -ua, -split_file, -treat_file) %>%   pivot_longer(cols = c(mean, sd), names_to = "metric", values_to = "metric_value") %>%   filter(startsWith(var, "str_")) %>%   # filter(var == "str_1",   #        metric == "sd") %>%   ggplot(aes(x = as.factor(confound_value), y = metric_value, fill = as.factor(filter))) +   geom_boxplot() +   facet_grid(cols = vars(var),              rows = vars(metric),              scales = "free")}
```

```{r} base_plot %>%    filter(str_detect(disturbance, "low", negate = T)) %>%    select(starts_with("str_"), disturbance) %>%    pivot_longer(starts_with("str_")) %>%    ggplot() +    geom_histogram(aes(x = value, col = disturbance, fill = disturbance)) +    facet_grid(cols = vars(name),              rows = vars(disturbance),              scales = "free_y")}
```

```{r} treat_plot %>%    mutate(across(dhi_1:all_6, \(x) round(x, 2))) %>%    group_by(str_1, str_2) %>%    filter(n() == 1) %>%    select(elev_cv:total_biomass, str_1, str_2) %>%    ungroup() %>%    summarize(across(starts_with("str"), .fns = list(mean = mean, sd = sd)))}
```

```{r} treat_plot %>%    summarize(across(CumDHI:total_biomass, .fns = list(mean = mean, sd = sd), .names = "{.col}-{.fn}")) %>%    pivot_longer(everything()) %>%    separate(name, into = c("var", "metric"), sep = "-") %>%   mutate(value = ifelse(var == "elev_p95", value / 10, value)) %>%   pivot_wider(names_from = metric, values_from = value) %>%   mutate(cv = sd / mean)}
```
